# Database Schema Rules

- Every table MUST have an autoincrement integer ID as primary key (NOT NULL)
- Every table MUST have `created` and `updated` DateTime fields that auto-update

# Database Migration Rules

## The Core Principle: Migrations Must Be Idempotent and Handle Partial Failure States

Migrations can fail partway through execution, leaving the database in an inconsistent state:
- New tables/indexes may have been created
- Old tables/indexes may still exist
- Schema version may not have been updated
- Data may be partially migrated

## The Root Cause of Migration Failures

When writing migrations, we mistakenly assumed:
1. **Clean state assumption**: That migrations always start from a clean, known state
2. **Atomic operation assumption**: That migrations either complete fully or roll back completely
3. **No cleanup needed**: That we can create new objects without checking for existing artifacts

In reality, failed migrations leave artifacts that must be cleaned up before retrying.

## The Rule: Always Clean Up Before Creating, But NEVER Drop Production Tables

WRONG (assumes clean state and drops tables):
```python
# Create new table
conn.execute(text("CREATE TABLE new_table (...)"))
conn.execute(text("CREATE INDEX ix_new_table_id ON new_table (id)"))
# Migrate data
conn.execute(text("INSERT INTO new_table SELECT ... FROM old_table"))
# Drop old table - DANGEROUS IN PRODUCTION!
conn.execute(text("DROP TABLE old_table"))
# Rename
conn.execute(text("ALTER TABLE new_table RENAME TO final_table"))
```

WRONG (drops tables without verification):
```python
# Clean up any artifacts from previous failed attempts FIRST
conn.execute(text("DROP TABLE IF EXISTS new_table"))
conn.execute(text("DROP TABLE IF EXISTS final_table"))
# Drop old table - STILL DANGEROUS!
conn.execute(text("DROP TABLE IF EXISTS old_table"))
```

RIGHT (handles partial failure AND preserves data):
```python
# SAFETY: Backup existing table if it has data
if "final_table" in existing_tables:
    existing_count = conn.execute(text("SELECT COUNT(*) FROM final_table")).scalar()
    if existing_count > 0:
        logger.warning(f"Backing up existing final_table with {existing_count} rows...")
        conn.execute(text("DROP TABLE IF EXISTS final_table_backup_vN"))
        conn.execute(text("CREATE TABLE final_table_backup_vN AS SELECT * FROM final_table"))

# Clean up intermediate artifacts from previous failed attempts (safe to drop)
conn.execute(text("DROP TABLE IF EXISTS new_table"))
conn.execute(text("DROP INDEX IF EXISTS ix_new_table_id"))

# Create new table
conn.execute(text("CREATE TABLE new_table (...)"))
conn.execute(text("CREATE INDEX ix_new_table_id ON new_table (id)"))

# Migrate data
conn.execute(text("INSERT INTO new_table SELECT ... FROM old_table"))

# VERIFY: Check that migration succeeded before touching old table
migrated_count = conn.execute(text("SELECT COUNT(*) FROM new_table")).scalar()
original_count = conn.execute(text("SELECT COUNT(*) FROM old_table")).scalar()
if migrated_count != original_count:
    raise Exception(f"Migration verification failed: {migrated_count} != {original_count}")

# SAFETY: Rename old table to backup (NEVER drop in production)
logger.info("Backing up old_table to old_table_backup_vN...")
conn.execute(text("DROP TABLE IF EXISTS old_table_backup_vN"))
conn.execute(text("ALTER TABLE old_table RENAME TO old_table_backup_vN"))

# Only drop intermediate/empty tables, never production data tables
if "final_table" in existing_tables and existing_count == 0:
    conn.execute(text("DROP TABLE IF EXISTS final_table"))

# Rename new table
conn.execute(text("ALTER TABLE new_table RENAME TO final_table"))
logger.info("Migration complete. Old tables backed up with _backup_vN suffix.")
```

## Why This Matters

When a migration fails:
- The database is left in an inconsistent state
- Schema version is not updated (still at old version)
- On next startup, migration tries again
- If we don't clean up artifacts, we get "already exists" errors
- User must manually fix database or we must handle it in code

## The Fix Pattern

1. **Backup before modifying**: Always backup existing tables with data before replacing them
2. **Verify before dropping**: Check row counts and data integrity before removing old tables
3. **Rename, don't drop**: Rename old tables to `_backup_vN` instead of dropping them (allows recovery)
4. **Only drop intermediate tables**: Only drop empty/intermediate tables from failed migrations, never production data
5. **Check for both old and new**: Don't just check for old state - also check for partial new state
6. **Make migrations idempotent**: They should be safe to run multiple times
7. **Extensive logging**: Log every step so you can trace what happened if something goes wrong

## Example: Table Rename Migration

When migrating from `old_table` to `new_table`:
- **Backup** `new_table` if it exists with data (to `new_table_backup_vN`)
- **Drop** only intermediate tables from failed attempts (`new_table_temp`, `new_table_new`)
- **Drop** only empty indexes that might exist independently
- **Create** fresh `new_table_new`
- **Migrate** data from `old_table` to `new_table_new`
- **Verify** row counts match before proceeding
- **Rename** `old_table` to `old_table_backup_vN` (NEVER drop)
- **Rename** `new_table_new` to `new_table`

This ensures the migration works whether:
- It's the first run (clean state)
- It's a retry after partial failure (artifacts exist)
- It's a retry after complete failure (both old and new exist)
- **And most importantly**: Data is always preserved in backup tables for recovery
